{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01cb58e",
   "metadata": {},
   "source": [
    "# Building AI-Powered semantic product catalog search \n",
    "### Using a pretrained LLM and Amazon Aurora PostgreSQL extension `pgvector` \n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Architecture](#Architecture)\n",
    "1. [Setup](#Setup)\n",
    "1. [Amazon Bedrock Model Hosting](#Amazon-Bedrock-Model-Hosting)\n",
    "1. [Load data into PostgreSQL](#Open-source-extension-pgvector-in-PostgreSQL)\n",
    "1. [Evaluate Search Results](#Evaluate-PostgreSQL-vector-Search-Results)\n",
    "\n",
    "## Background\n",
    "\n",
    "\n",
    "Semantic search is a type of search technique that aims to understand the intent and context of a user's query, rather than simply matching keywords or phrases. It goes beyond traditional keyword-based search by considering the meaning of words, the relationships between them, and the overall context of the query to deliver more relevant search results. Semantic search is important because it can help users to find the information they are looking for more quickly and easily.\n",
    "\n",
    "Here are some examples of how semantic search is used today:\n",
    "- Amazon uses semantic search to help customers find the products they are looking for. For example, if you search for \"blue running shoes,\" Amazon will return results for shoes that are both blue and designed for running, even if you didn't use both of those keywords in your query.\n",
    "- Netflix uses semantic search to recommend movies and TV shows to its users. For example, if you watch a lot of documentaries, Netflix will recommend other documentaries that you may be interested in.\n",
    "- Google uses semantic search to improve the relevance of its search results. For example, if you search for \"capital of France,\" Google will return results for Paris, even though you didn't explicitly mention Paris in your query.\n",
    "\n",
    "\n",
    "In this notebook, we'll build the core components of a textually similar Products. Often people don't know what exactly they are looking for and in that case they just type an item description and hope it will retrieve similar items. Othertimes, they have a photo of a product and looking for similar products matching those items.\n",
    "\n",
    "One of the core components of searching textually similar items is a fixed length sentence/word embedding i.e. a  “feature vector” that corresponds to that text. The reference word/sentence embedding typically are generated offline and must be stored so they can be efficiently searched. In this use case we are using a pretrained SentenceTransformer model `amazon.titan-embed-text-v1` from [Amazon Titan](https://aws.amazon.com/bedrock/titan/). \n",
    "\n",
    "To enable efficient searches for textually similar items, we'll use [Amazon Bedrock](https://aws.amazon.com/bedrock/) to generate fixed length sentence embeddings i.e “feature vectors” and use the Nearest Neighbor search in Amazon Aurora for PostgreSQL using the extension `pgvector`. The PostgreSQL `pgvector` extension lets you store and search for points in vector space and find the \"nearest neighbors\" for those points. Use cases include recommendations (for example, an \"other songs you might like\" feature in a music application), image recognition, and fraud detection.\n",
    "\n",
    "Here are the steps we'll follow to build textually similar items: \n",
    "- Generate feature vectors for the products description from kaggle dataset  using Amazon Bedrock. \n",
    "- Store the generated vectors in Amazon Aurora for PostgreSQL as vector datatype along with the metadata \n",
    "- Explore some sample text queries, and visualize the results.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "![](./images/arch_product_recommendation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae57bd",
   "metadata": {},
   "source": [
    "**Step 1.** We will download the Kaggle dataset and generate embeddings using `amazon.titan-embed-text-v1` Sentence Transformer model through Amazon Bedrock and store it in the Amazon Aurora PostgreSQL instance with pgvector extension\n",
    " \n",
    "**Step 2.** Search for a product with a keyword, which will be converted to embeddings and searched in the Amazon Aurora PostgreSQL database with Approximate Nearest Search and provide the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7045906",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install required python libraries for the workshop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f11c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pgvector pandarallel langchain boto3 asyncpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f3cadd",
   "metadata": {},
   "source": [
    "### Downloading Amazon Product Catalog from kaggle\n",
    "\n",
    "The [dataset](https://www.kaggle.com/datasets/promptcloud/amazon-product-dataset-2020) consists of 10000+ Amazon products along with the different descriptions of the product. The data was already downloaded as a csv file and we will load it into pandas dataframe to further process it. We will be combining the data in the colums `About Product`, `Product Specification` and `Technical Details` as `all_descriptions` to be used to convert to vector embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc29ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data of csv\n",
    "df = pd.read_csv('data/amazon.csv')\n",
    "df = df[['Uniq Id','Product Name','Category','About Product','Product Specification','Technical Details','Image']]\n",
    "\n",
    "df = df.dropna(subset=['About Product'])\n",
    "df = df.fillna('')\n",
    "df.rename(columns={'Uniq Id': 'id', \n",
    "                   'Product Name': 'product_name',\n",
    "                   'Category':'category',\n",
    "                   'About Product':'product_description',\n",
    "                   'Product Specification':'product_specification',\n",
    "                   'Technical Details':'product_details',\n",
    "                   'Image':'image_url'}, inplace=True)\n",
    "\n",
    "df['all_descriptions'] = df['product_description'] + df['product_specification'] + df['product_details']\n",
    "\n",
    "print(\"Total number of records : {}\".format(len(df.index)))\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa2f4b",
   "metadata": {},
   "source": [
    "## Amazon Bedrock Model Hosting\n",
    "\n",
    "In this section we will deploy the pretrained `amazon.titan-embed-text-v1` from Amazon Titan SentenceTransformer model into Amazon Bedrock and generate 1536 dimensional vector embeddings for our product catalog descriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b6c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "text_embeddings_model = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db6a36",
   "metadata": {},
   "source": [
    "Function to convert the text into vector embeddings. This function will be called for all the individual product descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_pooling(query):\n",
    "    descriptions_embeddings = text_embeddings_model.embed_query(query)\n",
    "    return descriptions_embeddings\n",
    "\n",
    "descriptions_embeddings = cls_pooling(\"Sample text to convert\")\n",
    "print (\"Number of text dimensions : {}\".format(len(descriptions_embeddings)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e0f848",
   "metadata": {},
   "source": [
    "In this code block, we will scan through all the data in the dataframe for the text stored in the `all_decriptions` column and convert it as embeddings using Amazon Bedrock realtime inference endpoint and store it as `description_embeddings` column in the same dataframe. We will use the number of paralleism based on the number of CPU's in the jupyter notebook. If you want to add additional worker processes, simply uncomment the line `pandarallel.initialize(progress_bar=True, nb_workers=10)` where you can provide the number of worker process to speed up the embeddings generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce3ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please re-run the cell if it fails.\n",
    "# Perform a job using realtime inference to generate embeddings ~ 2 min.\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "#pandarallel.initialize(progress_bar=True, nb_workers=10)\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "def generate_embeddings(data):\n",
    "    return cls_pooling(data)\n",
    "  \n",
    "# Generate Embeddings for all the products \n",
    "df['description_embeddings'] = df['all_descriptions'].parallel_apply(generate_embeddings)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e107d",
   "metadata": {},
   "source": [
    "## Open-source extension pgvector in PostgreSQL\n",
    "\n",
    "pgvector is an open-source extension for PostgreSQL that allows you to store and search vector embeddings for exact and approximate nearest neighbors. It is designed to work seamlessly with other PostgreSQL features, including indexing and querying.\n",
    "\n",
    "One of the key benefits of using pgvector is that it allows you to perform similarity searches on large datasets quickly and efficiently. This is particularly useful in industries like e-commerce, where businesses need to be able to quickly search through large product catalogs to find the items that best match a customer's preferences. It supports exact and approximate nearest neighbor search, L2 distance, inner product, and cosine distance.\n",
    "\n",
    "To further optimize your searches, you can also use pgvector's indexing features. By creating indexes on your vector data, you can speed up your searches and reduce the amount of time it takes to find the nearest neighbors to a given vector.\n",
    "\n",
    "In this step we'll get all the product descriptions of *Amazon Products* dataset and store those embeddings into Amazon Aurora PostgreSQL vector type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9579b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code block to load the products dinto Amazon Aurora PostgreSQL database with pgvector extension ~ 30sec\n",
    "\n",
    "import asyncpg\n",
    "from pgvector.asyncpg import register_vector\n",
    "\n",
    "client = boto3.client('secretsmanager')\n",
    "response = client.get_secret_value(SecretId='dat303-staging-apgpg-pgvector-secret')\n",
    "database_secrets = json.loads(response['SecretString'])\n",
    "\n",
    "dbhost = database_secrets['host']\n",
    "dbport = database_secrets['port']\n",
    "dbuser = database_secrets['username']\n",
    "dbpass = database_secrets['password']\n",
    "\n",
    "async def load_data():\n",
    "    \n",
    "    conn = await asyncpg.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport)\n",
    "    await register_vector(conn)\n",
    "   \n",
    "    await conn.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    await conn.execute(\"DROP TABLE IF EXISTS products;\")\n",
    "    await conn.execute(\"\"\"CREATE TABLE IF NOT EXISTS products(\n",
    "                           id text primary key, \n",
    "                           product_name text, \n",
    "                           category text, \n",
    "                           product_description text, \n",
    "                           product_specification text,\n",
    "                           product_details text,   \n",
    "                           image_url text,\n",
    "                           description_embeddings vector(1536));\"\"\")\n",
    "\n",
    "    for _, x in df.iterrows():\n",
    "        await conn.execute(\"\"\"INSERT INTO products\n",
    "                          (id, product_name, category, product_description, product_specification, product_details, image_url, description_embeddings) \n",
    "                          VALUES($1, $2, $3, $4, $5, $6, $7, $8);\"\"\", \n",
    "                          x.get('id'), x.get('product_name'), x.get('category'), x.get('product_description'), x.get('product_specification'), x.get('product_details'), x.get('image_url'), x.get('description_embeddings'))\n",
    "\n",
    "    \n",
    "    await conn.execute(\"\"\"CREATE INDEX ON products \n",
    "                       USING ivfflat (description_embeddings vector_l2_ops) WITH (lists = 100);\"\"\")\n",
    "\n",
    "    await conn.execute(\"VACUUM ANALYZE products;\")\n",
    "    await conn.close()\n",
    "\n",
    "await load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a93851",
   "metadata": {},
   "source": [
    "## Evaluate PostgreSQL vector Search Results\n",
    "\n",
    "In this step we will use Amazon Bedrock realtime inference to generate embeddings for the query and use the embeddings to search the Amazon Aurora PostgreSQL to retrive the nearest neighbours and retrive the relevent product images along with its descriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a72e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "\n",
    "async def search_data(embedding):\n",
    "    conn = await asyncpg.connect(host=dbhost, user=dbuser, password=dbpass, port=dbport)\n",
    "    await register_vector(conn)\n",
    "    \n",
    "    results = await conn.fetch(\"\"\"SELECT id, image_url, product_description,product_details\n",
    "                                  FROM products \n",
    "                                  ORDER BY description_embeddings <-> $1 limit 3;\"\"\",np.array(embedding))\n",
    "\n",
    "    img_td = \"\"\n",
    "    for x in results:\n",
    "        url = x[1].split(\"|\")[0]\n",
    "        img_td = img_td + \"\"\"<tr><td><img src={} width=\"330\"></td>\"\"\".format(url)\n",
    "        img_td = img_td + \"\"\"<td style=\"text-align: left; vertical-align: middle;\"> <p>{} {}</p></td></tr>\"\"\".format(str(x[2]),str(x[3]))\n",
    "        \n",
    "    display(HTML(\"\"\"<table>{}</table>\"\"\".format(img_td)))\n",
    "\n",
    "\n",
    "async def similarity_search(search_text):\n",
    "    embedding = cls_pooling(search_text)\n",
    "    await search_data(embedding)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8812e7",
   "metadata": {},
   "source": [
    "Using the above function `similarity_search` , lets do some search on the product catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await similarity_search(\"Video games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab838a1",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this workshop you have experiemented how semantic search works in searching product catalog for an e-commerce application. \n",
    "\n",
    "### Take aways\n",
    "- Adapt this notebook to experiment with different models available through Amazon Bedrock such as Anthropic Claude and AI21 Labs Jurassic models.\n",
    "- Change the input dataset and experiment with your organizational data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
